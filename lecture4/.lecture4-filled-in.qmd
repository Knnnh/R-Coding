---
title: "Lecture 4"
author: "Marc Kaufmann"
date: "30/01/2024"
output: html
---

Let's continue with chapter 5 of R4DS.

# mutate()

Let us create a narrower tibble with fewer columns so we can see what mutate does.

```{r}
library(nycflights13)

(flights_small <- select(flights,
                        year:day, 
                        ends_with("delay"), 
                        distance,
                        air_time))
```

Let us create a new column that computes catch up and the speed in miles:

```{r catch-up-and-speed}
mutate(flights_small, 
       catchup = dep_delay - arr_delay,
       speed_miles = (distance/air_time) * 60)
```

Since I don't know what speed in miles per hours is, let's convert that:

```{r convert-units}
mutate(
  flights_small,
  speed_km = (distance * 1.61/air_time) * 60
)
```

Magic numbers in code are great. Every one loves them. Not. They are evil and 
you should exorcise them:

```{r magic-numbers}
KM_PER_MILE <- 1.61

mutate(
  flights_small,
  speed_km = (distance * KM_PER_MILE/air_time) * 60
)
```
  
For complicated computations, it is clearer if you create intermediate results: 

```{r intermediate-results}
mutate(
  flights_small,
  distance_km = distance * KM_PER_MILE,
  air_time_hours = air_time / 60,
  speed_km = distance_km / air_time_hours
)
```

If you only want to keep the new variables, use `transmute`:

```{r transmute}
transmute(
  flights_small,
  distance_km = distance * KM_PER_MILE,
  air_time_hours = air_time / 60,
  speed_km = distance_km / air_time_hours
)
```

# Vectorized Operations

Vectorized operations are operations that take a vector as an argument and return
a vector of the same length. Standard arithmetic functions (+, *, etc) are 
vectorized, as are functions such as `log()`, `log2()`, etc.

Let us use that to extract the hours and minutes from `dep_time` (HHMM):

```{r hours-minutes}
transmute(
  flights,
  dep_time,
  dep_hour = dep_time %/% 100,
  dep_minutes = dep_time %% 100
)
```

Several other useful functions are `lag`, `lead`, and a variety of cumulative 
and aggregate functions, and the `n:m` notation is useful to create vectors of
consecutive integers:

```{r lag-lead}
(x <- c(0,1,2,3,4,5,6,7,8,9))
(y <- 0:9)
(z <- seq(0,9))

(lag(y))
(lag(lag(y)))
(lead(y))

cumsum(x)
cumprod(x)
cumprod(lead(x))
?cummin
?cummax
cummean(x)
```

Logical operators also return vectors when comparing vectors: 

```{r logical-operators}
x > 3
x > y
x == y
```

But you may wonder: what do some of these even mean?

```{r logical-ops-meaning}
x == c(2,4)
x > c(2,4,6)
```

Finally, you will often want to rank observations:

```{r ranking}
y <- c(10, 5, 6, 3, 7)
min_rank(y)

# Can you figure out from playing around with min_rank() how it works exactly?
min_rank(c(y, 7))
rank(c(y, 7))
```

## What is not a vectorized operation?

If you use a non-vectorized operation, things can go wrong if you try to use
it in a mutate, although functions that return a single item will simply return 
a vector with that single item repeated when a vector is expected:

```{r non-vectorized}
library(nycflights13)
library(tidyverse)
c(2,4)^2 # This is vectorized
mean(x)
c(TRUE, FALSE) && c(TRUE, TRUE) # `&&` expects a single element

# What happens when we try this on a dataframe
transmute(flights, delay = mean(arr_delay, na.rm = TRUE))
transmute(flights, arr_delay > 120 && dep_delay > 120)
```

Notice that the first does not throw an error, because you might have wanted to
compute the overall mean - but that's not always what you want.

# Class Exercises

**Exercise:** Create several ranges with the n:m notation, i.e. 2:4, 4:8, etc.           Try to find out whether you can also take negative ranges and descending. Read
?":" for help.

**Exercise:** Use `slice()` to choose the first 10 rows of flights.

**Exercises (for practice):** Do the following exercises from 5.5.2:
- Exercise 1
- Exercise 2
- Exercise 4
Hint: When you get stuck, try the following two strategies:
1. Take a single row, and work it out by hand
2. Create a variable my_flights which contains only a few rows (4 to 10).
Work out a solution for my_flights, where you can check every step.

# summarise()

```{r useless-summary}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
```

How... useful. Might as well have done:

```{r mean-directly}
mean(flights$dep_delay, na.rm = TRUE)
```

Reminder: `<data-frame>$<column-name>` returns the column `<column-name>` from 
`<data-frame>`, which is a quick way to select a column.

Note that this is different from using `select` on a column:
```{r try}
mean(select(flights, dep_delay), na.rm = TRUE)
```

Huh? What's going on here? 

```{r select-vs-dollar}
flights$dep_delay
select(flights, dep_delay)
```

Aha, we should have guessed, since select returns a *data frame*,
but `mean` expects a vector. A data frame of 1 column is not the same as 
a vector column.

So, what else can we use `summarise` for? To make it useful, we neeed its friend,
`group_by`:

```{r group-by}
by_day <- group_by(flights, year, month, day)
by_day
```

Looks distinctly the same. But it really isn't!

```{r useful-command}
summarise(
  group_by(flights, year, month, day), 
  delay = mean(dep_delay, na.rm = TRUE)
)

# Or, using the pipe
flights |>
  group_by(year, month, day) |>
  summarise(
    delay = mean(dep_delay, na.rm = TRUE)
  )
```

## Chapter 5.6.1 of R4DS

Let's explore link between distance and average delay for every location. What that means is that we want to know the average delay for every destination. Then, once we have that, we want to see how the distance to this location is related to the delay to this location.

```{r dist-delay-by-location}
by_destination <- group_by(flights, dest)
flights_delay <- summarise(
  by_destination,
  avg_arr_delay = mean(arr_delay, na.rm = TRUE)
)
flights_delay
```

OK, we need the distance too, or else there is not much to plot.

```{r dist-delay-by-location2}
(flights_delay <- summarise(
  by_destination,
  avg_arr_delay = mean(arr_delay, na.rm = TRUE),
  distance = mean(distance, na.rm = TRUE) # Somewhat of a hack
))

p <- ggplot(data = flights_delay,
            mapping = aes(x = distance, y = avg_arr_delay))
p + geom_point() + geom_smooth()

(flights_delay <- summarise(by_destination,
                    count = n(), 
                    avg_arr_delay = mean(arr_delay, na.rm = TRUE),
                    distance = mean(distance, na.rm = TRUE)))

p <- ggplot(data = flights_delay,
            mapping = aes(x = distance, y = avg_arr_delay))
p + geom_point(mapping = aes(size = count), alpha = 0.2) +
  geom_smooth()
```

We used the function `n`, which is special and works only inside of `summarize`:

```{r n}
n()
```

**Optional Exercise (harder):** The above smoothing does not take into account the number of flights per location - we only plot points by weight. A location with 1 flight matters as much for smoothing as a location with 300. 

That is rarely what we want when smoothing globally. Read the following code, to see if you understand how it works. 

Let's plot the original data, without first taking means by group

```{r opt-exercise}
# Woah, that looks different! (And ugly.)
p2 <- ggplot(data = flights,
             mapping = aes(x = distance, y = arr_delay))
p2 + geom_point(alpha = 0.2) + geom_smooth()

# Now let's plot points by location as before, but run geom_smooth on whole dataset
p2 + geom_point(data = flights_delay, aes(y = avg_arr_delay, size = count), alpha = 0.3) +
  geom_smooth()
# So, not too misleading, but still...
```

# Doing this with a pipe, and filtering out destinations with 
# - less than 20 flights
# - to HNL (Honululu), since it's by far the furthest
# Note: I am not a big fan of dropping things that 'look too different'.
# You should do such robustness checks, but you shouldn't start there. 

```{r hnl}
delays <- flights %>% 
  group_by(dest) %>%
  summarise(
    avg_arr_delay = mean(arr_delay, na.rm = TRUE),
    count = n(),
    distance = mean(distance, na.rm = TRUE)
    ) %>%
  filter( count > 20, dest != "HNL")
```

**Exercise:** Rewrite the above command without the pipe. Which one do you find easier to read?

## 5.6.2 Missing values

```{r missing-values}
not_missing <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))
```

**Exercise:** Does the above command also drop observations that miss only the arr_delay but have a dep_delay? Are there any observations in the dataset for which only dep_delay or arr_delay is missing, but not both?

## 5.6.3 Counts

Average delay by airplane (identified by tailnum), plot density.
Start with freqpoly, then zoom in on that part of the graph that we are interested:

```{r counts}
not_missing %>%
  group_by(tailnum) %>%
  summarise(avg_delay = mean(dep_delay)) %>%
  ggplot(mapping = aes(x = delay)) + 
  geom_histogram(binwidth = 10)
```

Plot the number of flights per airplane against delay:

```{r flights-against-delays}
not_missing %>%
  group_by(tailnum) %>%
  summarise(
    count = n(),
    avg_delay = mean(arr_delay)
    ) %>%
  ggplot(mapping = aes(x = avg_delay, y = count)) + 
  geom_point(alpha = 0.1)
```
         
Since I am filtering the same thing all the time, let's store it in a variable and drop the rest:

```{r store-filtered}
not_missing_planes <- not_missing |>
  group_by(tailnum) |>
  summarise(
    count = n(),
    avg_delay = mean(arr_delay),
    delay_median = median(arr_delay)
    )
```

Get the median delay for each airplane:

```{r median-delay}
ggplot(data = not_missing_planes) + 
  geom_histogram(mapping = aes(x = delay_median)) + 
  geom_histogram(mapping = aes(x = avg_delay), color = 'yellow', alpha = 0.3)
```

Filter the airplanes that fly rarely and pipe them into ggplot which gets plussed into geoms. Try a few values for how many flights one should have done

```{r}
not_missing_planes %>%
  filter(count > 5) %>%
  ggplot(mapping = aes(x = avg_delay)) + 
  geom_histogram()
```

# Exercises (Optional)

1. Read/Skim Chapter 5 of Grolemund and Wickham parts 1 through 4 (including select) of Grolemund and Wickham for anything we did not cover. 
2. Do all the left over exercises from this week in this script. 
3. Read/skim the chapter 5 from 'R for Data Science' to see what is available. Don't try to remember everything, but you should be able to remember what is possible so that you can find the commands again should you need them in the future. 
4. Document 4 errors and warnings you actually hit during the week. 
If you do *not* hit that many errors or receive such warnings, congratulations.